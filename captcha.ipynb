{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: '../input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m\"\u001b[39;49m\u001b[39m../input\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m     14\u001b[0m \u001b[39m# Any results you write to the current directory are saved as output.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: '../input'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import callbacks\n",
    "import os\n",
    "import cv2\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "#Init main values\n",
    "symbols = string.ascii_lowercase + \"0123456789\" # All symbols captcha can contain\n",
    "num_symbols = len(symbols)\n",
    "img_shape = (50, 200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(num_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "    conv1 = layers.Conv2D(16, (3, 3), padding='same', activation='relu')(img)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    conv2 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, activation='relu')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    model = Model(img, outs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: '../input/captcha-version-2-images/samples/samples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[39m# Return final data\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m X, y\n\u001b[1;32m---> 25\u001b[0m X, y \u001b[39m=\u001b[39m preprocess_data()\n\u001b[0;32m     26\u001b[0m X_train, y_train \u001b[39m=\u001b[39m X[:\u001b[39m970\u001b[39m], y[:, :\u001b[39m970\u001b[39m]\n\u001b[0;32m     27\u001b[0m X_test, y_test \u001b[39m=\u001b[39m X[\u001b[39m970\u001b[39m:], y[:, \u001b[39m970\u001b[39m:]\n",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_data\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     n_samples \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m'\u001b[39;49m\u001b[39m../input/captcha-version-2-images/samples/samples\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m      3\u001b[0m     X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n_samples, \u001b[39m50\u001b[39m, \u001b[39m200\u001b[39m, \u001b[39m1\u001b[39m)) \u001b[39m#1070*50*200\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m5\u001b[39m, n_samples, num_symbols)) \u001b[39m#5*1070*36\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: '../input/captcha-version-2-images/samples/samples'"
     ]
    }
   ],
   "source": [
    "def preprocess_data():\n",
    "    n_samples = len(os.listdir('../input/captcha-version-2-images/samples/samples'))\n",
    "    X = np.zeros((n_samples, 50, 200, 1)) #1070*50*200\n",
    "    y = np.zeros((5, n_samples, num_symbols)) #5*1070*36\n",
    "\n",
    "    for i, pic in enumerate(os.listdir('../input/captcha-version-2-images/samples/samples')):\n",
    "        # Read image as grayscale\n",
    "        img = cv2.imread(os.path.join('../input/captcha-version-2-images/samples/samples', pic), cv2.IMREAD_GRAYSCALE)\n",
    "        pic_target = pic[:-4]\n",
    "        if len(pic_target) < 6:\n",
    "            # Scale and reshape image\n",
    "            img = img / 255.0\n",
    "            img = np.reshape(img, (50, 200, 1))\n",
    "            # Define targets and code them using OneHotEncoding\n",
    "            targs = np.zeros((5, num_symbols))\n",
    "            for j, l in enumerate(pic_target):\n",
    "                ind = symbols.find(l)\n",
    "                targs[j, ind] = 1\n",
    "            X[i] = img\n",
    "            y[:, i] = targs\n",
    "    \n",
    "    # Return final data\n",
    "    return X, y\n",
    "\n",
    "X, y = preprocess_data()\n",
    "X_train, y_train = X[:970], y[:, :970]\n",
    "X_test, y_test = X[970:], y[:, 970:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Newcondaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62dca923bc8e3398b303a1becbc544787bd21d3664b6926ec2e3bb435ac39159"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
